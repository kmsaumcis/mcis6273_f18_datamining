{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["# MCIS6273 Data Mining (Prof. Maull) / Fall 2018 / HW0\n", "\n", "**This assignment is worth up to 20 POINTS to your grade total if you complete it on time.**\n", "\n", "| Points <br/>Possible | Due Date | Time Commitment <br/>(estimated) |\n", "|:---------------:|:--------:|:---------------:|\n", "| 20 | Sunday, Sep 09 @ Midnight | _up to_ 20 hours |\n", "\n", "\n", "* **GRADING:** Grading will be aligned with the completeness of the objectives.\n", "\n", "* **INDEPENDENT WORK:** Copying, cheating, plagiarism  and academic dishonesty _are not tolerated_ by Univerisity or course policy.  Please see the syllabus for the full departmental and University statement on the academic code of honor.\n", "\n", "## OBJECTIVES\n", "* Familiarize yourself with the JupyterLab environment\n", "\n", "* Familiarize yourself with Github and basic git\n", "\n", "* Explore JupyterHub Linux console integrating what you learned in the prior parts of this homework\n", "\n", "* Explore Python for basic text mining\n", "\n", "* Explore Python for data munging and analysis, with an introduction to JSON and Pandas\n", "\n", "## WHAT TO TURN IN\n", "You are being encouraged to turn the assignment in using the provided\n", "Jupyter Notebook.  To do so, make a directory in your Lab environment called\n", "`homework/hw0`.   Put all of your files in that directory.  Then zip that directory,\n", "rename it with your name as the first part of the filename (e.g. `maull_hw0_files.zip`), then\n", "download it to your local machine, then upload the `.zip` to Blackboard.\n", "\n", "If you do not know how to do this, please ask, or visit one of the many tutorials out there\n", "on the basics of using zip in Linux.\n", "\n", "## ASSIGNMENT TASKS\n", "### (5%) Familiarize yourself with the JupyterLab environment \n", "\n", "[Jupyter (https://jupyter.org)](https://jupyter.org) is the core platform we will be using in this course and\n", "is the platform of choice for data scientists around the world.  We have a JupyterLab\n", "setup for this course so that we can operate in a cloud-hosted environment, free from\n", "some of the resource contraints of running Jupyter on your local machine (though you are free to set\n", "it up and seek my advice if you desire to do that).\n", "\n", "The Jupyter envitonment we have setup can be found here [https://js-16-117.jetstream-cloud.org/](https://js-16-117.jetstream-cloud.org/).\n", "_You must contact me directly (and immediately) for your login credentials._\n", "\n", "We will be using the [Anaconda (https://anaconda.com)](https://anaconda.com) distribution of Python for our course.\n", "\n", "As you will soon find out Notebooks are an incredibly effective way to mix code with narrative\n", "and you can create cells that are entirely code or entirely Markdown.  Markdown (MD or md) is\n", "a highly readable text format that allows for easy documentation of text files, while allowing\n", "for HTML-based rendering of the text in a way that is style-independent.\n", "\n", "We will be using Markdown frequently in this course, and you will learn that there are many different\n", "\"flavors\" or Markdown.  We will only be using the basic flavor, but you will benefit from exploring\n", "the \"Github flavored\" Markdown, though you will not be responsible for using it in this course -- on the\n", "\"basic\" flavor.\n", "\n", "&#167;  **THERE IS NOTHING TO TURN IN FOR THIS PART.** Play with and become familiar with the basic functions of the Lab environment at [https://js-16-117.jetstream-cloud.org/](https://js-16-117.jetstream-cloud.org/).\n", "\n", "\n", "&#167;  **PLEASE _TURN IN A MARKDOWN DOCUMENT_ WITH 3 SENTENCES/FRAGMENTS THAT ANSWER THE FOLLOWING QUESTION:**\n", "\n", "* **What do you wish to accomplish this semester in Data Mining?**\n", "\n", "Read the documentation for basic Markdown [here](https://www.markdownguide.org/basic-syntax). \n", "Turn in the text `.md` file *not* the processed `.html`.  In whatever you turn in, \n", "you must show the use of *ALL* the following:\n", "\n", "* headings (one level is fine),\n", "* bullets,\n", "* bold and italics\n", "\n", "Again, the content of your document needs to address the question above.  **You will lose points**  if you do not do that.\n", "\n", "\n", "\n", "### (5%) Familiarize yourself with Github and basic git \n", "\n", "[Github (https://github.com)](https://github.com) is the _de facto_ platform for open source software in the world based\n", "on the very popular [git (https://git-scm.org)](https://git-scm.org) version control system. Git has a sophisticated set\n", "of tools for version control based on the concept of local repositories for fast commits and remote\n", "repositories only when collaboration and remote synchronization is necessary.  Github enhances git by providing\n", "tools and online hosting of public and private repositories to encourage and promote sharing and collaboration.\n", "Github hosts some of the world's most widely used open source software.\n", "\n", "**If you are already familiar with git and Github, then this part will be very easy!**\n", "\n", "&#167;  **CREATE A GITHUB.COM ACCOUNT AND RECORD THE URL TO YOUR ACCOUNT.**  It is OK if you already have an account, \n", "record the account URL either way. Use your `.edu` email address -- you will be able to get free private repositories\n", "for as long as you are a student with that email address.  Enjoy this perk while you can -- private repositories\n", "start at around $7/month when you are no longer using the `.edu` address.  Public repositories are always free.\n", "\n", "\n", "&#167;  **CREATE A PUBLIC GITHUB REPO NAME `\"MyDataSci2018\"` AND PLACE A README.MD FILE IN IT.**  \n", "Create your first file called\n", "`README.md` at the top level of the repository.  You can put whatever text you like in the file \n", "(If you like, use something like [lorem ipsum](https://lipsum.com/)\n", "to generate random sentences to place in the file.).\n", "Please include the link to **your** Github repository that now includes the minimal `README.md`. \n", "You don't have to have anything elaborate in that file or the repo. \n", "\n", "\n", "\n", "### (0%) Explore JupyterHub Linux console integrating what you learned in the prior parts of this homework \n", "\n", "The Linux console in JupyterLab is a great way to perform command-line tasks and is an essential tool\n", "for basic scripting that is part of a data scientist's toolkit.  Open a console in the lab environment\n", "and familiarize yourself with your files and basic commands using git as indicated below.\n", "\n", "1. In a new JupyterLab command line console, run the `git clone` command to clone the new\n", "  repository you created in the prior part.\n", "  You will want to read the documentation on this \n", "  command (try here [https://www.git-scm.com/docs/git-clone](https://www.git-scm.com/docs/git-clone) to get a good\n", "  start).\n", "2. Within the same console, modify your `README.md` file, check it in and push it back to your repository, using\n", "  `git push`.  Read the [documentation about `git push`](https://git-scm.com/docs/git-push).\n", "3. The commands `wget` and `curl` are useful for grabbing data and files from remote resources off the web.\n", "  Read the documentation on each of these commands by typing `man wget` or `man curl` in the terminal.\n", "  Make sure you pipe the output to a file or use the proper flags to do so.\n", "\n", "&#167;  **THERE IS NOTHING TO TURN IN FOR THIS PART.**\n", "\n", "\n", "\n", "### (45%) Explore Python for basic text mining \n", "\n", "Python is one of the most important languages in contemporary data science right now.  Its strengths are in\n", "readability and clarity of computational expressiveness.  There are a number of data science libraries and\n", "modules that we will be using throughout the course to achieve many important outcomes with Python.\n", "\n", "You will be tasked with writing two basic programs in Python using Jupyter Lab.  For starters,\n", "here are a few recommended resources you are encouraged to use though you are free to use whatever\n", "resources you find useful:\n", "\n", "* [Python website (https://python.org)](https://python.org)\n", "* [Hitchhikers Guide to Python by Kenneth Reitz and Tanya Schlusser (https://docs.python-guide.org)](https://docs.python-guide.org)\n", "* [Think Python by Allen Downey (http://greenteapress.com/wp/think-python/)](http://greenteapress.com/wp/think-python/)\n", "\n", "For the first part of the assignment, you will be tasked with a \"warm up\" tapping into the text processing\n", "capabilities of Python.  Please turn in the code and answers according to the instructions.\n", "\n", "&#167;  **WRITE A PROGRAM IN YOUR JUPYTER NOTEBOOK TO KEEP TRACK OF THE FREQUENCY OF THE TOP 30 WORDS THAT END IN \"_ng_\"\n", "FOR THE FOLLOWING 3 BOOKS:**\n", "\n", "(_The top 30 should be sorted by descending frequency -- most frequent to least._)\n", "\n", "* The Republic by Plato [http://www.gutenberg.org/cache/epub/1497/pg1497.txt](http://www.gutenberg.org/cache/epub/1497/pg1497.txt)\n", "* Don Quixote by Miguel de Cervantes Saavedra [http://www.gutenberg.org/cache/epub/996/pg996.txt](http://www.gutenberg.org/cache/epub/996/pg996.txt)\n", "* The Strange Case Of Dr. Jekyll And Mr. Hyde by Robert Louis Stevenson [http://www.gutenberg.org/files/43/43-0.txt](http://www.gutenberg.org/files/43/43-0.txt)\n", "\n", "For this part we will be using the open and freely available \n", "[Gutenberg.org](https://Gutenberg.org), which contains a large number of \n", "books in the public domain available for reading (or whatever purpose).\n", "We will just grab the text documents we would like to analyze and process them, \n", "though you are welcome to hang out on Gutenberg and do some light evening \n", "reading whenever you have free time.  \n", "\n", "To speed things up, you can store the documents\n", "locally (grabbing them through `wget` or `curl`) or you can use the \n", "boilerplate code provided below that\n", "uses the `requests` library and loads the document files each time over the web.\n", "If you store them locally, you are\n", "still resposible for writing the code for reading and processing the documents. Either way, it is up to\n", "you how you'd like to craft your solution.\n", "\n", "If you find it useful, you are welcome to read the documentation\n", "for and use the [`Counter`](https://docs.python.org/3.6/library/collections.html?highlight=counter#collections.Counter) object that is part of the\n", "Collections module.  While `Counter` may be useful, it is not required\n", "and there is a solution without it that is equally elegant.  NOTE:\n", "you should **normalize the text** so that all words are lowercase and free\n", "of punctuation (commas, periods, dashes, semicolons, etc.).\n", "\n", "**Do not use any other text processing libraries beyond those\n", "provided within Python directly (the good news is that you won't\n", "have to, but ask me if you have any doubts).**  You also do not\n", "need to do any stripping of text from the preamble, introductory\n", "remarks, etc. from the documents. Process them as they are.\n", "\n", "You will also find that [`split()`](https://docs.python.org/3.6/library/stdtypes.html#str.split) is useful in\n", "accomplishing tasks for this part, and the [`requests`](http://docs.python-requests.org/en/master/)\n", "library is useful for grabbing the text directly from Gutenberg.org\n", "as shown in the demo code below, though you are free to use whatever\n", "HTTP library (e.g. [`urllib`](https://docs.python.org/3.6/library/urllib.html))\n", "you like.  Finally, you can consider normalizing text with the\n", "[`re`](https://) regular expressions library.  For example, you can\n", "remove all `,` (comma) from a word with `re.sub(r',','','thus,')`.  To extend that \n", "to all punctuation, read the documentation on character classes and\n", "punctuation [https://docs.python.org/2/library/re.html#regular-expression-syntax](https://docs.python.org/2/library/re.html#regular-expression-syntax).\n", "\n", "Your notebook should include the solution code and answers structured in a table like below:\n", "\n", "| document_1     | word count ending in _ng_ |\n", "|---------------:|:--------------------------|\n", "| ng_ending_word_1   |  `ng_ending_word1_count`            |\n", "| ng_ending_word_2   |  `ng_ending_word2_count`            |\n", "| ...                |  ...                                |\n", "| ng_ending_word_30   |  `ng_ending_word30_count`            |\n", "\n", "\n", "| document_2     | word count ending in _ng_ |\n", "|---------------:|:--------------------------|\n", "| ng_ending_word_1   |  `ng_ending_word1_count`            |\n", "| ng_ending_word_2   |  `ng_ending_word2_count`            |\n", "| ...                |  ...                                |\n", "| ng_ending_word_30   |  `ng_ending_word30_count`            |\n", "\n", "\n", "| document_3     | word count ending in _ng_ |\n", "|---------------:|:--------------------------|\n", "| ng_ending_word_1   |  `ng_ending_word1_count`            |\n", "| ng_ending_word_2   |  `ng_ending_word2_count`            |\n", "| ...                |  ...                                |\n", "| ng_ending_word_30   |  `ng_ending_word30_count`            |\n", "\n", "**>** _here is code using_ `requests` _to read in a text file from gutenberg.org and\n", "store it in a variable called_ `data`.\n", "\n", "```python\n", "import requests\n", "\n", "url = \"http://www.gutenberg.org/files/31475/31475-0.txt\"\n", "r = requests.get(url)\n", "\n", "if r.status_code == 200:\n", "   data = r.content\n", "\n", "   # YOUR CODE TO PROCESS THIS DOCUMENT\n", "\n", "else:\n", "   print(\"[warn] GET request did not return HTTP/200 (HTTP/{} returned instead\".format(r.status_code))\n", "```\n", "\n", "\n", "\n", "### (45%) Explore Python for data munging and analysis, with an introduction to JSON and Pandas \n", "\n", "\n", "Python's strengths shine when tasked with data munging and analysis.  In this section we will be\n", "working with a [dataset from the City of Baltimore Parks division]( https://data.baltimorecity.gov/) which\n", "maintains open, public datasets for all the public parks in the Baltimore area.  For the curious\n", "[such datasets on public parks are plentiful]() and vary in quality and detail.\n", "\n", "**Please familiarize yourself with the data here**  :\n", "\n", "[https://data.baltimorecity.gov/resource/4qnj-2zbc.json](https://data.baltimorecity.gov/resource/4qnj-2zbc.json)\n", "\n", "As you will notice the data is a JSON file.  If you are unfamiliar with JSON, please take a look at this\n", "resource: [the JSON specification](https://json.org).\n", "\n", "As you look at the data, you will notice that there are some key data missing, which will be important for\n", "answering our data-related questions later.  Let's enumerate what those issues are:\n", "\n", "1. the original JSON file contains the name and address of the park, but **there is no [Geolocation](https://www.wordnik.com/words/geolocation) data\n", "indicating the latitude and longitude of the park**.\n", "\n", "2. **the original JSON file has no ZIP code for the park** -- the address is complete, but without a ZIP code\n", "we will not be able to answer some critical questions later.\n", "\n", "**You will need to complete the following tasks which involve data extraction and manipulation in Python as well as answering specific questions about the data.**\n", "\n", "&#167;  **WRITE THE CODE IN YOUR NOTEBOOK TO ENRICH THE JSON SO IT INCLUDES OUR MISSING DATA.**  _You will need to perform the following steps_:\n", "\n", "1. **load the parks JSON file into memory** using `requests` or  by loading\n", "it directly from the file system,\n", "2. **iterate over the parks addresses and lookup the ZIP, latitude and longitude** using the census API,\n", "3. **update the in-memory JSON parks data with the ZIP, latitude and longitude**,\n", "4. **store the new JSON file locally** and name it `baltimore_parks_enriched.json`.\n", "\n", "\n", "We indicated above that the latitude and longitude of the parks were missing, but that there is\n", "an address.  Lucky for us, there are a host of free online APIs that allow us to fill in the\n", "missing pieces. The first API we will use is called the [Geocoder API](https://geocoding.geo.census.gov/)\n", "provided by the US Census,\n", "which allows us to query the API with a street address and get the\n", "ZIP, latitude and longitude of that address (among other things).\n", "\n", "\n", "**>** _Here is a code snippet you might like to study and use to craft your solution:_\n", "\n", "```python\n", "# a sample address\n", "addr = \"301 32nd St\"\n", "\n", "CENSUS_GEO_ADDR_ENDPOINT = \"https://geocoding.geo.census.gov/geocoder/locations/address\"\n", "r = requests \\\n", "      .get(\"{}?street={}&city=baltimore&state=MD&benchmark=9&format=json\" \\\n", "      .format(CENSUS_GEO_ADDR_ENDPOINT, addr)\n", "\n", "if r.status_code == 200:\n", "  data = r.json()\n", "\n", "  # grab the first matching result, we're pretty confident in the matching for this part\n", "  data['result']['addressMatches'][0]\n", "\n", "  # YOUR CODE TO EXTRACT/INSERT THE MATCHING DATA (e.g. ZIP, LAT, LON)\n", "else:\n", "   print(\"[warn] GET request did not return HTTP/200 (HTTP/{} returned instead\".format(r.status_code))\n", "\n", "```\n", "\n", "Notice, we stored the output as a JSON object (`data = r.json()`).\n", "You will need to familiarize yourself with the [`json`](https://docs.python.org/3.6/library/json.html) library and\n", "the `json` object.  Specifically, how JSON is transformed as a\n", "Python dictionary allowing easy manipulation.  Look at an example usage\n", "of the `json` library: [https://docs.python-guide.org/scenarios/json/](https://docs.python-guide.org/scenarios/json/).\n", "There are also many other examples you can explore.\n", "\n", "\n", "&#167;  **USE PANDAS TO CONVERT THE JSON OBJECT TO A DATAFRAME AND ANSWER THE FOLLOWING QUESTIONS:**\n", "\n", "1. Which zipcode has the largest _number_ of parks?\n", "2. Which zipcode has the largest _acreage_ of parks?\n", "3. How many acres of parks are in zipcode 21229?\n", "4. What is the average acreage of parks in zipcode 21215?\n", "\n", "To answer these questions, you'll need to dive further into Pandas, which is\n", "the standard tool in the Python data science stack for loading, manipulating,\n", "transforming, analyzing and preparing data as input to other tools such as\n", "[Numpy (http://www.numpy.org/)](http://www.numpy.org/), \n", "[SciKitLearn (http://scikit-learn.org/stable/index.html)](http://scikit-learn.org/stable/index.html), \n", "[NLTK (http://www.nltk.org/)](http://www.nltk.org/) and others.\n", "\n", "For this assignment, you will only need to learn how to load and select data using Pandas.\n", "\n", "**LOADING DATA**\n", "The core data structure in Pandas is the `DataFrame`.  You will need to visit\n", "the Pandas documentation [(http://pandas.pydata.org/pandas-docs)](http://pandas.pydata.org/pandas-docs)\n", "to learn more about the library, but to help you along with a hint, read the\n", "documentation on the [`pandas.read_json()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_json.html) method.\n", "\n", "**SELECTING DATA**\n", "The [tutorial here on indexing and selecting](http://pandas.pydata.org/pandas-docs/stable/indexing.html)\n", "should be of great use in understanding how to index and select subsets of\n", "the data to answer the questions.\n", "\n", "**EXAMPLE CODE**\n", "\n", "**>** _Here is example code that should give you clues about the structure\n", "of your code for this part._\n", "\n", "```python\n", "import pandas as pd\n", "\n", "df = pandas.read_json('your_json_file.json')\n", "\n", "# code for question 1 ... and so on\n", "\n", "```\n", "\n", "\n", "&#167;  **BUILD A   \"DISTANCE TABLE\" (WITH A PANDAS DATAFRAME) OF PARK DISTANCES\n", "USING THE HAVERSINE FORMULA.** _Your solution should:_\n", "\n", "1. create and calculate a distance table from each park to one another,\n", "so that **for a given park** you can **compute the\n", "distances to all other parks**.  Your solution can just involve\n", "the `(lat,lon)` for each park as a tuple. The\n", "diagonal of your table will, of course, be zero\n", "(the distance from the park to itself is 0).  The row and column labels\n", "of the table need only be the index of the park in the prior exercise.\n", "\n", "To use the [Haversine formula](https://en.wikipedia.org/wiki/Haversine_formula)\n", "to compute the distance (in miles) between lat/lon park pairs -- study its\n", "distance calculation given by:\n", "\n", "$$\n", "H_{d}\\big((\\varphi_1, \\lambda_1), (\\varphi_2, \\lambda_2)\\big) = 2r \\arcsin \\bigg(\n", "\\sqrt {\n", "(\\sin^2 \\bigg(\\frac{\\varphi_2 - \\varphi_1}{2} \\bigg) +\n", "\\cos(\\varphi_1)\\cos(\\varphi_2)\\sin^2\\bigg(\\frac{\\lambda_2 - \\lambda_1}{2}\\bigg)\n", "}\n", "\\bigg)\n", "$$\n", "\n", "Where $\\varphi$ represent the longitude and $\\lambda$ the latitude for\n", "two points $p_1 = (\\varphi_1, \\lambda_1)$ and $p_2 = (\\varphi_2, \\lambda_2)$, \n", "where $p_1$ and $p_2$ are the latitude and longitude of two parks.\n", "\n", "You can write the Python for the Haversine function on your own or\n", "you can integrate the one I have coded [here](https://gist.github.com/kmsaumcis/4066b56ebbff3ea3b515f617622a8854).\n", "Just remember $r=3961$ and that you will need to convert the\n", "degrees input (lat/lon) to radians, using the [`math.radians`](https://docs.python.org/3.6/library/math.html#math.radians)\n", "function.  Your Haversine function should take two pairs of\n", "lat/lon coordinates and return their distance in miles.\n", "\n", "To create the table, you will simply load the park data from\n", "the previous section, iterate over all park pairs\n", "and compute the Haversine distance and appropriately update\n", "the table by index. **HINT:** Simply implement this as\n", "nested loop, though be patient with the execution time\n", "since there are 275 parks (~75K distance pairs) and\n", "the loop $O(n^2)$.\n", "\n", "The final DataFame (table) will look like an\n", "$n \\times m$ matrix so that the $n$th row and $m$th column represent\n", "the distance from park $n$ to park $m$ using the Haversine distance.\n", "\n", "**HINT:** Make sure you do not delete or alter the table from the\n", "previous answer as you will need it to make reference to indices\n", "of the park names to correctly answer the questions for this part.\n", "\n", "Here is what your DataFrame will start to look like:\n", "\n", "|  | 0     |     1    |      2    |     3   |     4    |     5   | ... |\n", "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n", "|0 |  0        |  0.939578 |  3.37182 |  1.78964 |  1.80147 |  3.40832 | $\\cdots$ |\n", "|1 |  0.939578 |  0        |  4.01058 |  2.18962 |  1.36067 |  2.72742 |  |\n", "|2 |  3.37182  |  4.01058  |  0       |  4.73579 |  3.52097 |  4.77002 | $\\vdots$ |\n", "|3 |  1.78964  |  2.18962  |  4.73579 |  0       |  3.46797 |  4.91533 | |\n", "|4 |  1.80147  |  1.36067  |  3.52097 |  3.46797 |  0       |  1.66318 | |\n", "|5 |  3.40832  |  2.72742  |  4.77002 |  4.91533 |  1.66318 |  0       | $\\cdots$ |\n", "| $\\cdots$ | | | | $\\cdots$ | | | $\\cdots$ |\n", "\n", "\n", "&#167;  **NOW THAT YOU HAVE ALL THE DISTANCES BETWEEN PARKS PLEASE ANSWER THE FOLLOWING QUESTIONS:**\n", "\n", "1. What are the 5 closest parks to 32nd Street Park?\n", "2. What is the park with the _highest_ average distance from its closest 12 parks?\n", "3. What is the park with the _lowest_ average distance from its closest 12 parks?\n", "\n", "\n"]}], "metadata": {"anaconda-cloud": {}, "kernelspec": {"display_name": "Python [default]", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.1"}, "toc": {"colors": {"hover_highlight": "#DAA520", "navigate_num": "#000000", "navigate_text": "#333333", "running_highlight": "#FF0000", "selected_highlight": "#FFD700", "sidebar_border": "#EEEEEE", "wrapper_background": "#FFFFFF"}, "moveMenuLeft": true, "nav_menu": {"height": "12px", "width": "252px"}, "navigate_menu": true, "number_sections": false, "sideBar": true, "threshold": "1", "toc_cell": false, "toc_section_display": "block", "toc_window_display": true, "widenNotebook": false}}, "nbformat": 4, "nbformat_minor": 0}